\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath} 
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{algorithm,algorithmic}
\usepackage{caption}


\title{Distributed PageRank - Final Report}
\author{Aaron Myers, Megan Ruthven}

\begin{document}
\maketitle
\tableofcontents
\pagebreak
\section{Introduction}
The purpose of this project is to investigate distributed PageRank by applying Pagerank methods currently in use in the multi-thread case to the distributed scenario and determine if these methods can be scaled to multi-machine systems. We also take a method that has already proven to be effective in the distributed setting and apply it to the Pagerank problem (ADMM \cite{ADMM}. Immediately below is a more detailed description of each approach. The primary metrics for performace will be: speedup, scalability, and ease of coding/understanding, all of which will be explained in the results section. The last metric is included to suggest that ease of coding and understanding of a method has an impact on the adoption rate in industry and therefore should be included in this investigation.
\begin{enumerate}
\item Apply ADMM \cite{ADMM} to the linear form of the Pagerank problem (Ax=b) and determine if there is value in taking this approach rather than other methods (Power Iteration, Linear solver with GMRES, BICGStab, etc). Since it is more difficult to apply a data-drive approach to the separated minimization problems, we expect this method to have less than great performance for speed, but higher performance for ease of coding/understanding.

\item Approach the problem with the typical power iteration combined with data-driven and topology-driven approaches (listed below) to iterating along with appropriate load balancing. The idea is to maintain a worklist that contains only nodes whose change in pagerank value is above a set threshold, we will refer to this as $"$delta updating$"$. This method is primarily taken from \cite{Joyce} and we will simply apply this method in the distributed setting with MPI. There are both major and subtle differences between each of the approaches below and we will go into greater detail about these differences later in this paper, althought a more thorough explaination can be found in \cite{Joyce}.
  \begin{enumerate}
	\item Push based: 
	 \item Pull based:
	 \item Push-pull based:
	 \item Topology driven:
  \end{enumerate}
\end{enumerate}

\section{Linear System Approach}
This approach requires that we form the PageRank problem into a linear system (Ax=b) in which case solving for x would provide the list of PageRank values. Below is a simple derivation taken from \cite{Fast Parallel}.
\begin{center}
\begin{align}
	P' &= P + dv^{T} \\
	P'' &= cP' + (1-c)ev^{T} \\
	x^{k+1} &= P''^{T}x^{k}
\end{align}

\end{center}
Where P$'$ and P$''$ are the modified PageRank matrices that have the modifications necessary to create a connected graph and add a personalization factor and e is a vector of all 1's, resulting in equation 3, the Power Iteration approach to Pagerank.
\newline
\linebreak
Given the additional information below, we can derive the linear system for Pagerank.


\begin{center}
\begin{align}
  e^{T}x & = x^{T}e = \|x\|_{1} = \|x\| \\
  d^{T}x &= \| x\| - \| P^{T}x\| \\
  x &= [cP^{T} + c(vd^{T}) + (1-c)ve^{T}]x
\end{align}
\end{center}

Combining the information above, we arrive at the following equation:

\begin{center}
\begin{equation}
  (I-cP^{T})x = kv
\end{equation}
\end{center}
We now have Pagerank in a linear form (Ax=b), where A = I-c$P^{T}$ and kv = b. If in addition, we normalize x, we have the following:

\begin{center}
  \begin{align}
	k &= \|x\| - c \|P^{T}x\| = (1-c) \|x\| + d^{T}x \\	
	k &= 1-c 
  \end{align}
\end{center}



\subsection{ADMM}

Most of the articles we encountered for parallel pagerank used Jacobi iteration or some Krylov Subspace method (GMRES, BiCGSTAB, etc), but we attempted to implement something we were introduce to in this course, namely ADMM \cite{ADMM}. This is an extremely simple way to parallelize a linear solve and we will compare these results to GMRES and BiCGSTAB for the same problem parallelizing using PETSc. We expect ADMM to have worse performance, but we would like to quantify the loss in accuracy/time relatvie to the ease of implementation.
\newline
\linebreak
Below is a brief description of the ADMM idea and algorithm.
\newline
We take the linear problem and split up the data accordingly:
\begin{center}
\begin{align}
	A &= \left[ A_{1} ... A_{n} \right]' \\
	b &= \left[ b_{1} ... b_{n} \right]' 
\end{align}
\end{center}
Our origninal minimization of Ax-b with a certain norm and regulariztion on x now becomes:

\begin{center}
\begin{align}
	&minimize \: \: \: \sum_{i=1}^{N} l_{i}(A_{i}x_{i} - b_{i}) + r(z) \\
	&subject \: \: \: to \: \: \: x_{i} - z = 0 \: \: \: \forall i
\end{align}
\end{center}
Where $x_{i}$ are local variables that we force to match the global solution z at each step.
\newline
The resulting algorithm, using the augmented lagrangian presented in the ADMM method \cite{ADMM}, is as follows:

\begin{center}
\begin{algorithm}
\caption{ADMM Iteration}
\begin{algorithmic}[1]
	\STATE $x_{i}^{k+1} = argmin_{x} \: \: \: l_{i}(A_{i}x_{i} - b_{i}) + \frac{\rho}{2} \| x_{i}^{k} - z^{k} - u_{i}^{k} \|_{2}^{2}$ 
	\STATE $z^{k+1} = argmin_{z} \: \: \: r(z) + \frac{N \rho}{x} \| z^{k} - \bar{x}^{k+1} - \bar{u}^{k} \|_{2}^{2} $
	\STATE $u_{i}^{k+1} = u_{i}^{k} + x_{i}^{k+1} - z^{k+1} $ 
  \end{algorithmic}
\end{algorithm}
\end{center}

Where $u_{i}^{k} = \frac{1}{\rho} y_{i}^{k}$



% Here we talk about typical methods to solve linear equations -------------------------------------------
\subsection{ADMM Results Compared to other Linear methods}
Below are the inital results for ADMM programmed in Matlab for a simple data set (a disconnected synthetic 11 node graph). 

\begin{center}
\captionof{table}{Linear Method Table}
\begin{tabular}{l || r}
	\hline\hline
	\multicolumn{2}{c}{5 iter results} \\
	\hline\hline
	Method  & $\|\hat{x} - x\| $ \\
	\hline
	GMRES & 0.0047  \\
	BiCGSTAB & 0.0056  \\
	ADMM & 0.0079  \\
\end{tabular}
\end{center}
\newpage
%Power iteration section with distributed programming ------------------------------------
\section{Power Iteration Approach}
In addition to the Linear system, we will approach Distributed PageRank as a Graph with power iteration. We have slightly modified the approach (inspired by \cite{Joyce}) by first computing all updated pagerank values and for every subsequent update, we only modify the pagerank of the nodes pointed to by an update change in value above some certain threshold. We will also use the magnitude of these changes to prioritize a worklist for the algorithm to execute. 
\newline
\begin{algorithm}
\caption{Power Iteration with Worklist}
\begin{algorithmic}[1]
  \STATE Initialize x, $\delta$ (threshold)
  \STATE Compute Px for all nodes
  \WHILE{Worklist is not empty}
  \IF{$x_{i}$ in worklist}
    \STATE take $x_{i}$ off the worklist
	\STATE $x_{i}^{new} = (1-\alpha)*P_{i}*x + \frac{\alpha}{\#[x]}$
    \IF{$|x_{i}^{new} - x_{i}| > \delta$}
		\STATE $x_{i} = x_{i}^{new}$
		\STATE add $x_{j}$ onto worklist : $\forall x_{i} \to x_{j}$
	\ENDIF
  \ENDIF
  \ENDWHILE
\end{algorithmic}
\end{algorithm}
\newline

\subsection{Power Graph Results}
We implemented the two algorithms of pagerank with openMP, and compared the time to convergence. On the A dataset from HW4, the pagerank values converged in fewer iterations (25 to 20) and on average, takes less time to run one iteration (0.189 to 0.095 seconds) running on 16 threads. This resulted in a total calculation time of 4.72 seconds for the baseline power iterations and 1.90 seconds for the delta method. A summary table is below.

\begin{center}
\captionof{table}{Power Iteration - A}
\begin{tabular}{l || c | r}
	\hline
	\multicolumn{3}{c}{Method Comparison} \\
	\hline\hline
	Method & Iteration Count & Time(s) \\
	\hline\hline
	Power Iteration & 25 & 4.72 \\
	Delta Update & 20 & 1.90 \\
\end{tabular}
\end{center}


\begin{center}
\captionof{table}{Power Iteration - Friendster}
\begin{tabular}{l || c | r}
	\hline
	\multicolumn{3}{c}{Method Comparison} \\
	\hline\hline
	Method & Iteration Count & Time(s) \\
	\hline\hline
	Power Iteration & 23 & 49.6 \\
	Delta Update & 30 & 19.5 \\
\end{tabular}
\end{center}
\section{Next Steps}

Now that we have seen the value of both ADMM and data-driven PageRank, our next steps will involve parallelizing using MPI

\begin{enumerate}
	\item Parallelize the ADMM method using MPI and compare the results to running GMRES and BiCGSTAB with PETSc
	\item Parallelize the data-driven PageRank problem using MPI and compare these results to other parallel Power Iteration approaches
	\item Collect all results and provide conclusions about all methods and the value that each provides.
\end{enumerate}

\subsection{Load Balancing}
We will also implement load balacing with both ADMM and the delta updating as described below.

\begin{enumerate}
	\item ADMM: each iteration, we will determine if the new local variable value has changed significantly. If so, it will be pushed to the master worklist to be operated on for the next iteration. If not, it will be removed from the worklist.
	\item Delta Updating: similarly, each iteration will check the updated value of the node and push it and its out-neighbors to the master worklist if above a certain threshold. This master worklist will have duplicated removed and will divide the work evenly across all computing nodes. Ideally, the more connected nodes would be sent to the same compute node so some type of clustering may be beneficial for this operation.
\end{enumerate}

\section{Related Work}


\section{Results}

\begin{thebibliography}{1}

\bibitem{Power Law Graphs} David Gleich, et al. {\em Scalable Computing for Power Law Graphs: Experience with Parallel PageRank}

\bibitem{Fast Parallel} David Gleich, et al. {\em Fast Parallel PageRank: A Linear System Approach} 

\bibitem{ADMM} Stephen Boyd, et al. {\em Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers} 

\bibitem{Joyce} Joyce Whang, et al. {\em Scalable Data-driven PageRank: Algorithms, System Issues '\&' Lessons Learned}
 
 \bibitem{MPIref} mcs.anl.gov {\em http://www.mcs.anl.gov/research/projects/mpi/tutorial/mpiexmpl/src/jacobicmpl/C/main.html}
 
 \bibitem{FSU} fsu.edu {\em http://people.sc.fsu.edu/~jburkardt/cppsrc/mpi/mpi.html}

 \bibitem{MPIPR} Xiaoyi (Eric) Li  {\em Parallel PageRank Computation using MPI}

 \bibitem{YahooPPR} David Gleich, Leonid Zhukov, Pavel Berkhin  {\em Fast Parallel PageRank: Methods and Evaluations}

 \bibitem{IndianaPPR} Shubhada Karavinkoppa and Jayesh Kawli  {\em Page Rank Algorithm Using MPI}

 \bibitem{MixedMPI} Bundit Manaskasemsak, Putchong Uthayopas, Arnon Rungsawang {\em A Mixed MPI-Thread Approach for Parallel Page Ranking Computation}

\end{thebibliography}

\end{document}
