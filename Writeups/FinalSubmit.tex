%\documentclass[a4paper,10pt]{article}
%\usepackage[utf8x]{inputenc}
%\usepackage{amsmath} 
%\usepackage{mathtools}
%\usepackage{amssymb}
%\usepackage{algorithm,algorithmic}
%\usepackage{caption}

\documentclass[letterpaper,12pt,onecolumn]{article}
\usepackage[margin=1in]{geometry} %one inch margins
\usepackage{amsmath,graphicx}
\usepackage{algorithm,algorithmic}


\geometry{verbose,margin=1in}

\title{Distributed PageRank - Final Report}
\author{Aaron Myers, Megan Ruthven}

\begin{document}
\maketitle
\tableofcontents
\pagebreak
\section{Introduction}
The purpose of this project is to investigate distributed PageRank by applying Pagerank methods currently in use in the multi-thread case and implement it in the distributed setting. It is to determine if these methods can be scaled to multi-machine systems. We also take a method that has already proven to be effective in the distributed setting and apply it to the Pagerank problem (ADMM <-- what does this stand for \cite{ADMM}). Immediately below is a more detailed description of each approach. The primary metrics for performace will be: speedup, scalability, and ease of implementation, all of which will be explained in the results section. The last metric is included to suggest that ease of coding and understanding of a method has an impact on the adoption rate in industry and therefore should be included in this investigation.

Apply ADMM \cite{ADMM} to the linear form of the Pagerank problem (Ax=b) and determine if there is value in taking this approach rather than other methods (Power Iteration, Linear solver with GMRES, BICGStab, etc). Since it is more difficult to apply a data-driven approach to the separated minimization problems, we expect this method to have less than great performance for speed, but higher performance for ease of coding/understanding.

Approach the problem with the typical power iteration combined with data-driven and topology-driven approaches (listed below) to iterating along with appropriate load balancing. The idea is to maintain a worklist that contains only nodes whose change in pagerank value is above a set threshold, we will refer to these as $"$data driven$"$ method. This method is primarily taken from~\cite{Joyce} and we addapted these methods in a distributed setting with MPI and openMP. There are both major and subtle differences between each of the approaches below and we will go into greater detail about these differences later in this paper, althought a more thorough explaination can be found in \cite{Joyce}.
  \begin{enumerate}
	 \item Topology driven:
	 \item Pull based:
	 \item Pull-Push based:
	\item Push based: 
  \end{enumerate}


\section{Linear System Approach}
This approach requires that we form the PageRank problem into a linear system (Ax=b) in which case solving for x would provide the list of PageRank values. Below is a simple derivation taken from \cite{Fast Parallel}.
\begin{center}
\begin{align}
	P' &= P + dv^{T} \\
	P'' &= cP' + (1-c)ev^{T} \\
	x^{k+1} &= P''^{T}x^{k}
\end{align}

\end{center}
Where P$'$ and P$''$ are the modified PageRank matrices that have the modifications necessary to create a connected graph and add a personalization factor and e is a vector of all 1's, resulting in equation 3, the Power Iteration approach to Pagerank.
\newline
\linebreak
Given the additional information below, we can derive the linear system for Pagerank.


\begin{center}
\begin{align}
  e^{T}x & = x^{T}e = \|x\|_{1} = \|x\| \\
  d^{T}x &= \| x\| - \| P^{T}x\| \\
  x &= [cP^{T} + c(vd^{T}) + (1-c)ve^{T}]x
\end{align}
\end{center}

Combining the information above, we arrive at the following equation:

\begin{center}
\begin{equation}
  (I-cP^{T})x = kv
\end{equation}
\end{center}
We now have Pagerank in a linear form (Ax=b), where A = I-c$P^{T}$ and kv = b. If in addition, we normalize x, we have the following:

\begin{center}
  \begin{align}
	k &= \|x\| - c \|P^{T}x\| = (1-c) \|x\| + d^{T}x \\	
	k &= 1-c 
  \end{align}
\end{center}



\subsection{ADMM}

Many of the articles we encountered for solving parallel pagerank in the linear form used Jacobi iteration or some Krylov Subspace method (GMRES, BiCGSTAB, etc), but we attempted to implement something we were introduce to in this course, namely ADMM \cite{ADMM}. This is an extremely simple way to parallelize a linear solve. This process attempts to split the linear problem into subsections, solve separately, and combine the information in a very specific way. 
We will compare these results to the implementation of GMRES and BiCGSTAB for the same problem parallelizing using PETSc \cite{Power Law Graphs}. We expect ADMM to have worse performance, measured by speedup, but we would like to quantify the loss in accuracy/time relative to the ease of implementation and scalability.
\newline
\linebreak
Below is a brief description of the ADMM idea and algorithm \cite{ADMM}.
\newline
We take the linear problem and split up the data accordingly:
\begin{center}
\begin{align}
	A &= \left[ A_{1} ... A_{n} \right]' \\
	b &= \left[ b_{1} ... b_{n} \right]' 
\end{align}
\end{center}
Our origninal minimization of Ax-b with a certain norm and regulariztion on x now becomes:

\begin{center}
\begin{align}
	&minimize \: \: \: \sum_{i=1}^{N} l_{i}(A_{i}x_{i} - b_{i}) + r(z) \\
	&subject \: \: \: to \: \: \: x_{i} - z = 0 \: \: \: \forall i
\end{align}
\end{center}
Where $x_{i}$ are local variables that we force to match the global solution z at each step and N is the number of processes used to solve the problem.
\newline
The resulting algorithm, using the augmented lagrangian presented in the ADMM method \cite{ADMM}, is as follows:

\begin{center}
\begin{algorithm}
\caption{ADMM Iteration}
\begin{algorithmic}[1]
	\STATE $x_{i}^{k+1} = argmin_{x} \: \: \: l_{i}(A_{i}x_{i} - b_{i}) + \frac{\rho}{2} \| x_{i}^{k} - z^{k} - u_{i}^{k} \|_{2}^{2}$ 
	\STATE $z^{k+1} = argmin_{z} \: \: \: r(z) + \frac{N \rho}{x} \| z^{k} - \bar{x}^{k+1} - \bar{u}^{k} \|_{2}^{2} $
	\STATE $u_{i}^{k+1} = u_{i}^{k} + x_{i}^{k+1} - z^{k+1} $ 
  \end{algorithmic}
\end{algorithm}
\end{center}

Where $u_{i}^{k} = \frac{1}{\rho} y_{i}^{k}$ and for our implementation, we chose the $L^{1}$ regularization term (also known as lasso) and used a gradient solver with Eigen to solve the minimization for x. Using the lasso regulariztion the z update becomes soft-thresholding update. Considering the Lasso method, the updated algorithm is below.

\begin{center}
\begin{algorithm}
\caption{ADMM Iteration with Lasso}
\begin{algorithmic}[1]
  \STATE $x_{i}^{k+1} = argmin_{x} \: \: \: \|(A_{i}x_{i} - b_{i})\|_{2}^{2} + \frac{\rho}{2} \| x_{i}^{k} - z^{k} - u_{i}^{k} \|_{2}^{2}$ 
  \STATE $z^{k+1} = S_{\lambda/\rho N} (\bar{x}^{k+1} - \bar{u}^{k})$
	\STATE $u_{i}^{k+1} = u_{i}^{k} + x_{i}^{k+1} - z^{k+1} $ 
  \end{algorithmic}
\end{algorithm}
\end{center}

Where S is defined componend-wise in the following way:
\begin{center}
	\begin{equation}
	  S_{\lambda/\rho N}(x_{i}) := (x_{i} - \frac{\lambda}{\rho N})_{+} - (-x_{i} - \frac{\lambda}{\rho N})_{+}
	\end{equation}
\end{center}

% Here we talk about typical methods to solve linear equations -------------------------------------------
\subsection{ADMM Results Compared to other Linear methods}
Below are the inital results for ADMM programmed in Matlab for a simple data set (a disconnected synthetic 11 node graph). 

\begin{center}
\captionof{table}{Linear Method Table}
\begin{tabular}{l || r}
	\hline\hline
	\multicolumn{2}{c}{5 iter results} \\
	\hline\hline
	Method  & $\|\hat{x} - x\| $ \\
	\hline
	GMRES & 0.0047  \\
	BiCGSTAB & 0.0056  \\
	ADMM & 0.0079  \\
\end{tabular}
\end{center}
\newpage
%Power iteration section with distributed programming ------------------------------------
\section{Power Iteration Approach - Delta Updating}
In addition to the Linear system, we have Distributed PageRank with power iteration. We use an approach (taken from \cite{Joyce}) by first computing all updated pagerank values and for every subsequent update, we only modify the pagerank of the outgoing nodes of a node whose updated pagerank has a value above some certain threshold. We will also use the magnitude of these changes to prioritize a worklist for the algorithm to execute. 
\newline
\begin{algorithm}
\caption{Power Iteration with Worklist}
\begin{algorithmic}[1]
  \STATE Initialize x, $\delta$ (threshold)
  \STATE Compute Px for all nodes
  \WHILE{Worklist is not empty}
  \IF{$x_{i}$ in worklist}
    \STATE take $x_{i}$ off the worklist
	\STATE $x_{i}^{new} = (1-\alpha)*P_{i}*x + \frac{\alpha}{\#[x]}$
    \IF{$|x_{i}^{new} - x_{i}| > \delta$}
		\STATE $x_{i} = x_{i}^{new}$
		\STATE add $x_{j}$ onto worklist : $\forall x_{i} \to x_{j}$
	\ENDIF
  \ENDIF
  \ENDWHILE
\end{algorithmic}
\end{algorithm}
\newline

\subsection{Power Iteration Results}
We implemented the the of the algorithms discussed in \cite{Joyce} in the distributed setting using MPI and MPI with openMP, and compared the time to convergence. On the A dataset from HW4, the pagerank values converged in fewer iterations (25 to 20) and on average, takes less time to run one iteration (0.189 to 0.095 seconds) running on 16 threads. This resulted in a total calculation time of 4.72 seconds for the baseline power iterations and 1.90 seconds for the delta method. A summary table is below.

\begin{center}
\captionof{table}{Power Iteration - A}
\begin{tabular}{l || c | r}
	\hline
	\multicolumn{3}{c}{Method Comparison} \\
	\hline\hline
	Method & Iteration Count & Time(s) \\
	\hline\hline
	Power Iteration & 25 & 4.72 \\
	Delta Update & 20 & 1.90 \\
\end{tabular}
\end{center}


\begin{center}
\captionof{table}{Power Iteration - Friendster}
\begin{tabular}{l || c | r}
	\hline
	\multicolumn{3}{c}{Method Comparison} \\
	\hline\hline
	Method & Iteration Count & Time(s) \\
	\hline\hline
	Power Iteration & 23 & 49.6 \\
	Delta Update & 30 & 19.5 \\
\end{tabular}
\end{center}
\section{Next Steps}

Now that we have seen the value of both ADMM and data-driven PageRank, our next steps will involve parallelizing using MPI

\begin{enumerate}
	\item Parallelize the ADMM method using MPI and compare the results to running GMRES and BiCGSTAB with PETSc
	\item Parallelize the data-driven PageRank problem using MPI and compare these results to other parallel Power Iteration approaches
	\item Collect all results and provide conclusions about all methods and the value that each provides.
\end{enumerate}

\subsection{Load Balancing}
We will also implement load balacing with both ADMM and the delta updating as described below.

\begin{enumerate}
	\item ADMM: each iteration, we will determine if the new local variable value has changed significantly. If so, it will be pushed to the master worklist to be operated on for the next iteration. If not, it will be removed from the worklist.
	\item Delta Updating: similarly, each iteration will check the updated value of the node and push it and its out-neighbors to the master worklist if above a certain threshold. This master worklist will have duplicated removed and will divide the work evenly across all computing nodes. Ideally, the more connected nodes would be sent to the same compute node so some type of clustering may be beneficial for this operation.
\end{enumerate}

\section{Related Work}


\section{Results}

\begin{thebibliography}{1}

\bibitem{Power Law Graphs} David Gleich, et al. {\em Scalable Computing for Power Law Graphs: Experience with Parallel PageRank}

\bibitem{Fast Parallel} David Gleich, et al. {\em Fast Parallel PageRank: A Linear System Approach} 

\bibitem{ADMM} Stephen Boyd, et al. {\em Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers} 

\bibitem{Joyce} Joyce Whang, et al. {\em Scalable Data-driven PageRank: Algorithms, System Issues '\&' Lessons Learned}
 
 \bibitem{MPIref} mcs.anl.gov {\em http://www.mcs.anl.gov/research/projects/mpi/tutorial/mpiexmpl/src/jacobicmpl/C/main.html}
 
 \bibitem{FSU} fsu.edu {\em http://people.sc.fsu.edu/~jburkardt/cppsrc/mpi/mpi.html}

 \bibitem{MPIPR} Xiaoyi (Eric) Li  {\em Parallel PageRank Computation using MPI}

 \bibitem{YahooPPR} David Gleich, Leonid Zhukov, Pavel Berkhin  {\em Fast Parallel PageRank: Methods and Evaluations}

 \bibitem{IndianaPPR} Shubhada Karavinkoppa and Jayesh Kawli  {\em Page Rank Algorithm Using MPI}

 \bibitem{MixedMPI} Bundit Manaskasemsak, Putchong Uthayopas, Arnon Rungsawang {\em A Mixed MPI-Thread Approach for Parallel Page Ranking Computation}

\end{thebibliography}

\end{document}
